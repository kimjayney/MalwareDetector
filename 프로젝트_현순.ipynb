{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "프로젝트_현순.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ov30fBh4Tdw"
      },
      "source": [
        "## 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwD0GFmz4XUr"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "import pandas as pd\n",
        "import peminer\n",
        "import csv\n",
        "\n",
        "\n",
        "# additional dependency..\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJYuB0FK4LJU"
      },
      "source": [
        "## 필요한 함수들 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8_WGudx4Seq"
      },
      "source": [
        "SEED = 41\n",
        "\n",
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_label_only_value(inputarr):\n",
        "    list = []\n",
        "    for line in inputarr:\n",
        "      fname, label = line.strip().split(\",\")\n",
        "      list.append(int(label))\n",
        "    return list \n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "\n",
        "    # 학습 알고리즘 불러오기\n",
        "    # 랜덤 포레스트 : rf\n",
        "    # 의사결정 트리 : dt\n",
        "    # lightgbm : lgb\n",
        "    # svm : svm\n",
        "    # logistic regression : lr\n",
        "    # knn : knn\n",
        "    # adaboost : adaboost\n",
        "    # mlp : mlp\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    # 학습\n",
        "    clf.fit(X_train, y_train) #rf 학습, n_estimators..이걸 어캐 해야하나..?\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    '''\n",
        "        학습된 머신러닝 모델로 검증 데이터를 검증하는 함수\n",
        "\t\n",
        "        :param X_test: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y_test: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    predict = model.predict(X_test)\n",
        "    print(\"예측\")\n",
        "    print(predict)\n",
        "    print(\"y_test\")\n",
        "    print(y_test)\n",
        "    print(\"정확도\", model.score(X_test, y_test))\n",
        "\n",
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    def get_custom_info(self):\n",
        "      custom = self.report\n",
        "      \n",
        "      vector = [\n",
        "        custom[\"FileHeader.Machine\"],\n",
        "        custom['FileHeader.Characteristics'],\n",
        "        custom['OptionalHeader.DllCharacteristics'],\n",
        "        custom['OptionalHeader.Subsystem'],\n",
        "        custom['OptionalHeader.ImageBase'],\n",
        "        custom['OptionalHeader.MajorSubsystemVersion']\n",
        "      ]\n",
        "      return vector\n",
        "\n",
        "    def process_report(self):\n",
        "        '''\n",
        "            커스텀 feature 로 시도..\n",
        "        '''\n",
        "        # self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        self.vector = self.get_custom_info()  \n",
        "        return self.vector\n",
        "\n",
        "    \n",
        "\n",
        "class EmberParser:\n",
        "    '''\n",
        "    예제에서 사용하지 않은 특징도 사용하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "        histogram = np.array(self.report[\"histogram\"])\n",
        "        total = histogram.sum()\n",
        "        vector = histogram / total\n",
        "        return vector.tolist()\n",
        "    \n",
        "    def get_string_info(self):\n",
        "        strings = self.report[\"strings\"]\n",
        "\n",
        "        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "        vector = [\n",
        "            strings['numstrings'], \n",
        "            strings['avlength'], \n",
        "            strings['printables'],\n",
        "            strings['entropy'], \n",
        "            strings['paths'], \n",
        "            strings['urls'],\n",
        "            strings['registry'], \n",
        "            strings['MZ']\n",
        "        ]\n",
        "        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "        return vector\n",
        "    \n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "\n",
        "    def process_report(self):\n",
        "        vector = []\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_histogram_info()\n",
        "        vector += self.get_string_info()\n",
        "        '''\n",
        "            특징 추가\n",
        "        '''\n",
        "        return vector\n",
        "    \n",
        "class PestudioParser:\n",
        "    '''\n",
        "        사용할 특징을 선택하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "# 피클 파일 로드\n",
        "def read_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# 피클 파일 저장\n",
        "def save_pickle(path, data):\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def select_feature(X, y, model):\n",
        "    '''\n",
        "        주어진 특징 벡터에서 특정 알고리즘 기반 특징 선택\n",
        "        \n",
        "        본 예제에서는 RFE 알고리즘 사용\n",
        "        https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE.fit_transform\n",
        "        \n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 특징 선택에 사용할 머신러닝 모델\n",
        "    '''\n",
        "    \n",
        "    model = load_model(model=model, random_state=SEED)\n",
        "    rfe = RFE(estimator=model)\n",
        "    return rfe.fit_transform(X, y)\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imlvj8BYeZNm"
      },
      "source": [
        "## 테스트데이터_정답.csv 파일 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpLPjzxecB7"
      },
      "source": [
        "file_list = os.listdir(\"./데이터/PEMINER/테스트데이터/\")  #sha256 파일이름 리스트\n",
        "f = open('./데이터/테스트데이터_정답.csv', 'wt', newline=\"\")\n",
        "writer = csv.writer(f)\n",
        "\n",
        "writer.writerow(['파일이름', '정답' ])\n",
        "lists = []\n",
        "for item in file_list:\n",
        "    sha256_filename = item.split(\".\")[0]\n",
        "    set_tf = ''\n",
        "    lists.append([sha256_filename,set_tf ]) \n",
        "\n",
        "writer.writerows(lists)\n",
        "\"Completed.\"\n",
        "f.close()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fPOt1J7K_Dm"
      },
      "source": [
        "## 데이터 전처리 작업을 해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKhnlB7LBZo"
      },
      "source": [
        "label_table = read_label_csv(\"./데이터/학습데이터_정답.csv\")\n",
        "label_table_test = read_label_csv(\"./데이터/테스트데이터_정답.csv\") \n",
        "# verify_table_test = read_label_csv(\"./데이터/검증데이터_정답.csv\")\n",
        "\n",
        "# PEMINER 에서 사용한 특징의 이름\n",
        "\n",
        "# 데이터의 특징 벡터 모음 : X\n",
        "# 데이터의 레이블 모음 : y\n",
        "X, y = [], []\n",
        "X_test_init , y_test_init = [], []\n",
        "# X_verify_init , y_verify_init = [], []\n",
        "\n",
        "# 첫번째 fname는 결과가 0이고 두번째 fname는 결과가 1임\n",
        "# for fname in label_table:\n",
        "\n",
        "index = 0\n",
        "for fname in label_table:\n",
        "    feature_vector = [] #특징 벡터를 저장할 공간\n",
        "    label = label_table[fname] # csv 파일 안에 1 , 0 이 들어가는 듯..\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"데이터/{data}/학습데이터/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report() \n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        " \n",
        "    X.append(feature_vector)\n",
        "    y.append(label)\n",
        "\n",
        "# 테스트 데이터에서 X 값만 Append()\n",
        "for fname in label_table_test:\n",
        "  feature_vector_test = [] #특징 벡터를 저장할 공간\n",
        "  for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"데이터/{data}/테스트데이터/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector_test += PeminerParser(path).process_report() \n",
        "        else:\n",
        "            feature_vector_test += EmberParser(path).process_report() \n",
        "        #print(feature_vector)\n",
        "  \n",
        "  X_test_init.append(feature_vector_test)\n",
        "\n",
        "# 검증 데이터 검증할 때만 주석해제\n",
        "# for fname in verify_table_test:\n",
        "#   feature_vector = []\n",
        "#   label = verify_table_test[fname]\n",
        "#   for data in [\"PEMINER\",\"EMBER\"]:\n",
        "#     path = f\"데이터/{data}/검증데이터/{fname}.json\"\n",
        "#     if data == \"PEMINER\":\n",
        "#       feature_vector += PeminerParser(path).process_report()\n",
        "#     else:\n",
        "#       feature_vector += EmberParser(path).process_report()\n",
        "#   X_verify_init.append(feature_vector)\n",
        "#   y_verify_init.append(label)\n",
        "\n",
        "# np.asarray(X).shape, np.asarray(y).shape #.shape 는 벡터가 몇차원인지 나타낸다..\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMtT9GPgKB7H"
      },
      "source": [
        "## 학습 전과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUaokgWityqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe3db53-ee6a-4a8b-9ab2-5550228d7fb2"
      },
      "source": [
        "np.set_printoptions(threshold=10000)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,  test_size=0.2)\n",
        "# x_train_verify, x_test_verify, y_train_verify, y_test_verify = train_test_split(X_verify_init, y_verify_init, test_size=0.2) #검증용임\n",
        "# X_train_realtest, X_test_realtest = train_test_split(X_test_init)  # useless\n",
        "print(len(X_test_init))\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=100) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t9DhT6-Gbdr"
      },
      "source": [
        "## 학습 수행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7rCr2GCGZ1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483f87fa-ff71-4ce5-8e1d-3513f4dd7d56"
      },
      "source": [
        "forest.fit(x_train, y_train)\n",
        "y_pred = forest.predict(x_test)\n",
        "\n",
        "# score_pred = forest.predict(x_test)\n",
        "\n",
        "print(\"정확도 : \", metrics.accuracy_score(y_test, y_pred))\n",
        "# print(\"정확도-검증: \" , metrics.accuracy_score(y_test_verify, score_pred )) #검증데이터로 정확도 내는코드\n",
        "# 학습한 모델로 테스트 데이터 예측한 것! -> 정확도는 안 나온다고 했음\n",
        "# print(X_test_init)\n",
        "\n",
        "y_pred_testdata = forest.predict(X_test_init)\n",
        "# print(y_pred_testdata)\n",
        "print(\"테스트데이터 예측값 길이 -> 정확도는 알 수가 없음..\")\n",
        "print(len(y_pred_testdata))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 :  0.94125\n",
            "테스트데이터 예측값 길이 -> 정확도는 알 수가 없음..\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2uI7ObAY0Dr"
      },
      "source": [
        "## 예측이 잘 되었는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2SIw26-TA9T"
      },
      "source": [
        "#print(\"정확도 : \", metrics.accuracy_score(y, y_pred))\n",
        "# print(np.take(y_pred_testdata, 7))\n",
        "y_pred_testdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBR6Ftf3uy3j"
      },
      "source": [
        "## 예측한 테스트데이터 값에 맞는 sha256 작성하기 (predict.csv 작성하기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwdGg2Uav90y"
      },
      "source": [
        "file_list = os.listdir(\"./데이터/PEMINER/테스트데이터/\")\n",
        "f = open('./데이터/predict.csv', 'wt', newline=\"\")\n",
        "writer = csv.writer(f)\n",
        "\n",
        "writer.writerow(['파일이름', '정답' ])\n",
        "lists = []\n",
        "y_pred_index = 0\n",
        "len(file_list)\n",
        "for item in file_list:\n",
        "    sha256_filename = item.split(\".\")[0]\n",
        "    set_tf = y_pred_testdata[y_pred_index]\n",
        "    lists.append([sha256_filename,set_tf ]) \n",
        "    y_pred_index = y_pred_index +1\n",
        "\n",
        "writer.writerows(lists)\n",
        "\"Completed.\"\n",
        "f.close()"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}